---
layout: post
title:  "IOS音频中断时创建视频问题"
image: ''
date:   2024-08-09 16:08:28
tags:
- Cocos
description: ''
categories: 
- Cocos
---
### 问题:IOS系统上滑显示WIFI面板、下滑锁屏、home键锁屏、跳转webview、接到短信或者电话都会触发音频中断通知。  
### 当音频中断之后,AudioEngine中会将openAL的当前上下文置为空,然后接到音频中断结束的时候恢复openAL的上下文。

### 而音频中断结束的回调有时候不会通知,所以这就导致需要应用自己判断并进行恢复openAL。



UIApplicationState 枚举在 iOS 开发中定义了三个状态，每个状态都有一个对应的整型值。  
这些枚举值在 UIApplication 类中定义如下：  
UIApplicationStateActive 的值是 0。  
UIApplicationStateInactive 的值是 1。  
UIApplicationStateBackground 的值是 2。  
UIApplicationStateActive：表示应用程序正在运行并处于活动状态。  
UIApplicationStateInactive：表示应用程序正在运行，但它并不是当前的活动应用程序，可能在处理中断或在后台。  
UIApplicationStateBackground：表示应用程序已经转到后台，用户看不到它的界面。  


即:如果应用处于中断的状态,并且state等于0或者1,那么就需要尝试进行恢复openAL。  
因为音频中断结束某些情况或者某些系统不会通知,所以这里也需要判断UIApplicationStateInactive  

PS:需要注意恢复失败的情况，另外IOS音频引擎使用的是openAL,那么视频中音频就不能用openAL重新创建一个上下文,
否则会出现两个上下文连接一个音频设备的问题

```obj-c
//active AVAudioSession
-(bool) setAudioSessionActive:(BOOL) active
{
    NSError *error = nil;
    BOOL success = [[AVAudioSession sharedInstance]
                    setCategory: AVAudioSessionCategoryPlayback
                    error: &error];
    
    if(!success)
    {
        ALOGD("setAudioSessionActive setCategory fail");
        return false;
    }
    
    NSError *errorss = nil;
    BOOL re = [[AVAudioSession sharedInstance] setActive:active error:&errorss];
    
    if(re == NO){
        ALOGE("setAudioSessionActive fail");
        return false;
    }
    if(errorss!=nil){
        
        return false;
    }
//
    ALOGD("setAudioSessionActive setActive OK");
    return true;
    
}

-(bool) audioSessionResume
{
    if(_interrupted)
    {
        NSLog(@"audioSessionResume");
        int state = (int)[UIApplication sharedApplication].applicationState;
        NSLog(@"audioSessionResume applicationState %d",state);
        
        if(![self setAudioSessionActive:YES])
        {
            return false;
        }
        auto alError = alGetError();
        if(alError != AL_NO_ERROR)
        {
            ALOGE("audioSessionResume before alcMakeContextCurrent! check error = %x", alError);
        }
        alcMakeContextCurrent(s_ALContext);
        alError = alGetError();
        if(alError != AL_NO_ERROR)
        {
            ALOGE("audioSessionResume failed! error = %x", alError);
            alcMakeContextCurrent(nullptr);
            return false;
        }

        NSLog(@"audioSessionResume complete");
        _interrupted = false;
        return true;
    }else{
        ALOGD("audioSessionResume no need");
    }
    return false;
}

bool AudioEngineImpl::fixinterrupt()
{
    if (!_interrupted) {
        return true;
    }
    UIApplicationState state = [UIApplication sharedApplication].applicationState;
    ALOGD("AudioEngineImpl::fixinterrupt applicationState %d",(int)state);
    if (state == UIApplicationStateActive or state == UIApplicationStateInactive) {
        [s_AudioEngineSessionHandler audioSessionResume];
    }

    if (_interrupted) {
        ALOGD("AudioEngineImpl::fixinterrupt interrupted true");
        return false;
    }
    return true;
}
```
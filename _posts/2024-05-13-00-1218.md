---
layout: post
title:  "音视频相关计算"
image: ''
date:   2024-05-13 10:09:15
tags:
- Cocos
description: ''
categories: 
- Cocos
---

# 1、音频流相关
采样率:对声音的模拟信号进行采样,即在一个连续的波函数上取一系列离散的点。

![采样率](..\assets\img\cocos\caiyanglv.png)

CD音质采样率为44.1KHz,同时也是所有android设备都支持的采样率 
__(比如有些设备的采样率播放一个不支持的采样率音频,那么就会出现声音异常,音调变快或者变慢或者其他情况)。__

码率(数据率):即1秒中的离散的点经过编码之后占用的存储空间大小。  
PCM音频流的码率: 采样率值×采样大小值×声道数 bps  
一个采样率为44.1KHz，采样大小为16bit，双声道的PCM编码的WAV文件，它的数据速率则为 44.1K×16×2 =1411.2 Kbps

MP3音频流码率: MP3 文件的数据率表示压缩后的音频数据传输速率 
__通常以比特率（bitrate）来表示，单位是千位每秒（kbps）或兆位每秒（Mbps）__  
MP3 是一种有损压缩的音频格式，它通过去除音频数据中的部分信息来减小文件大小，__因此数据率取决于压缩算法和设置的比特率__  
降低MP3文件的比特率可以降低文件大小,但是同时会损失一些细节,(比如有些语音类视频,降低比特率之后听起来就跟之前有明显差别)。  
__PS:不要通过降低采样率来降低文件大小,因为除了44.1KHz之外的采样率或多或少会有些设备不支持。__



## 音频帧的播放时长
ACC音频流

对采样率为44.1kHz的AAC音频进行解码时，一帧的解码时间须控制在23.22毫秒内。
通常是按1024个采样点一帧

分析：
1. AAC
一个AAC原始帧包含某段时间内1024个采样点相关数据。
用1024主要是因为AAC是用的1024点的mdct。
```
音频帧的播放时间=一个AAC帧对应的采样样本的个数/采样频率(单位为s)
```
采样率(samplerate)为 44100Hz，表示每秒 44100个采样点,
所以，根据公式,

```音频帧的播放时长 = 一个AAC帧对应的采样点个数 / 采样频率```
则，当前一帧的播放时间 = 1024 * 1000/44100= 23.22 ms(单位为ms)
48kHz采样率，
则，当前一帧的播放时间 = 1024 * 1000/48000= 21.333ms(单位为ms)
22.05kHz采样率，
则，当前一帧的播放时间 = 1024 * 1000/22050= 46.439ms(单位为ms)

2. MP3

mp3 每帧均为1152个字节，
则：
每帧播放时长 = 1152 * 1000 / sample_rate
例如：sample_rate = 44100HZ时，
计算出的时长为26.122ms，
这就是经常听到的mp3每帧播放时间固定为26ms的由来。

## 量化精度（位宽）
上图中，每一个红色的采样点，都需要用一个数值来表示大小，这个数值的数据类型大小可以是：4bit、8bit、16bit、32bit等等，位数越多，表示得就越精细，声音质量自然就越好，当然，数据量也会成倍增大。
常见的位宽是：8bit 或者 16bit


## 声道数（channels）
由于音频的采集和播放是可以叠加的，因此，可以同时从多个音频源采集声音，并分别输出到不同的扬声器，故声道数一般表示声音录制时的音源数量或回放时相应的扬声器数量。
单声道（Mono）和双声道（Stereo）比较常见，顾名思义，前者的声道数为1，后者为2  
PS:将双声道改为单声道可以降低音频文件大小


## 音频帧（frame）
是用于测量显示帧数的量度。  
所谓的测量单位为**每秒显示帧数**(Frames per Second，简称：FPS）或“赫兹”（Hz）。  

音频跟视频很不一样，视频每一帧就是一张图像，而从上面的正玄波可以看出，音频数据是流式的，本身没有明确的一帧帧的概念，在实际的应用中，为了音频算法处理/传输的方便，一般约定俗成取2.5ms~60ms为单位的数据量为一帧音频。

这个时间被称之为“采样时间”，其长度没有特别的标准，它是根据编×××和具体应用的需求来决定的，我们可以计算一下一帧音频帧的大小：  

假设某通道的音频信号是采样率为8kHz，位宽为16bit，20ms一帧，双通道，则一帧音频数据的大小为：  

```int size = 8000 x 16bit x 0.02s x 2 = 5120 bit = 640 byte```

## 音频数据压缩的原理(压缩冗余信息) 
1. 频谱掩蔽效应： 人耳所能察觉的声音信号的频率范围为**20Hz～20KHz**，在这个频率范围以外的音频信号属于冗余信号。
2. 时域掩蔽效应： 当强音信号和弱音信号同时出现时，弱信号会听不到，因此，弱音信号也属于冗余信号。

## 常见的音频压缩格式
常见的音频压缩格式： 
MP3，AAC，OGG，WMA，Opus，FLAC，APE，m4a，AMR，等等

# 2、OpenSL ES 两种播放方式

## 1. SL_DATAFORMAT_PCM
1. 解码 MP3 文件
    * 每个 MP3 文件在播放之前都需要通过解码器进行解码，生成 PCM 数据
2. 混音 PCM 数据
    * 解码后的 PCM 数据是未压缩的音频数据，代表每个声道的采样。
    * 如果你想同时播放多个 MP3 文件，你需要将它们解码后的 PCM 数据混合在一起。这个过程包括将多个音轨的 PCM 数据按比例（音量）加起来，然后输出到最终的音频缓冲区。
    * 需要注意的是，混音时要确保各个数据流的采样率和声道数一致，否则需要进行相应的转换  

**这种方式需要手动混音,同时也可以一边解码音频帧一边播放,但是需要自己处理解码(cocos目前不支持边解码边播放的PCM处理)**
## SL_DATALOCATOR_URI
* android使用这种方式播放音频时,音频的解码是由OpenSL ES 调用android底层的接口来解码的。  
* 混音则是由OpenSL ES底层框架来完成的。

```
在 Android 平台上，OpenSL ES 是通过调用底层的音频接口解码音频文件并将解码后的音频数据传递给 OpenSL ES 引擎，然后 OpenSL ES 引擎负责将音频数据混合并输出到音频设备。
```
__PS:但是由于OpenSL ES多线程处理有问题,导致销毁音频的时候底层解码线程还在工作或者正在初始化从而触发crash。__

**解决这个问题可以使用第一个方式自己处理边解码边播放,但是这种很麻烦，还需要兼容之前的混音处理。。。**